1_
• Direccion Logica:
• Es una direccion que enmascara o abstrae una direccion fısica
• Referencia a una localidad en memoria
• Se la debe traducir a una direccion fısica

• Direccion Fısica:
• Es la direccion real. Es con la que se accede efectivamente a
memoria
• Representa la direccion absoluta en memoria principal

La CPU trabaja con direcciones logicas. Para acceder a la
memoria se deben transformar en direcciones fısicas
El mapeo entre direcciones virtuales y fısicas se realiza
mediante hardware → MMU (Memory Management Unit)

2_ a)
• Particiones Fijas:• La memoria se divide en particiones o regiones de tama ̃no fijo
→ tama ̃nos iguales o diferentes
• Alojan un  ́unico proceso• Cada proceso se coloca en alguna partici ́on de acuerdo a alg ́un
criterio:• First Fit
• Best Fit
• Worst Fit
• Next Fit
• Particiones Din ́amicas:• Las particiones var ́ıan en tama ̃no y n ́umero
• Alojan un proceso cada una
• Cada partici ́on se genera en forma din ́amica del tama ̃no justo
que necesita el proceso

Particiones Fijas
Descripción:
La memoria principal se divide en un número fijo de particiones de tamaño predeterminado al iniciar el sistema.
Cada partición puede contener un proceso único.
Si el proceso necesita menos memoria que el tamaño de la partición, se desperdicia el espacio sobrante (fragmentación interna).

Ventajas:
Simple de implementar: Los tamaños de las particiones se establecen previamente.
Bajo overhead: La administración de la memoria es directa, ya que no se requieren cálculos complejos para ajustar las particiones.

Desventajas:
Fragmentación interna: Los procesos pequeños dejan partes de la memoria inutilizadas dentro de las particiones asignadas.
Falta de flexibilidad: Si un proceso es más grande que cualquier partición, no puede ser cargado, incluso si hay suficiente memoria disponible en total.

Particiones Dinámicas
Descripción:
La memoria principal se divide en particiones del tamaño exacto requerido por cada proceso en el momento de su asignación.
Se utiliza una técnica como First Fit, Best Fit, Next Fit o Worst Fit para encontrar un bloque de memoria adecuado.
A medida que los procesos terminan, se crean espacios vacíos que causan fragmentación externa.

Ventajas:
Mayor flexibilidad: Los procesos pueden ocupar exactamente la cantidad de memoria que necesitan, reduciendo la fragmentación interna.
Mejor uso de la memoria: Permite cargar procesos de diferentes tamaños siempre que haya espacio disponible.

Desventajas:
Fragmentación externa: Los bloques pequeños no utilizados entre particiones pueden volverse inutilizables con el tiempo.
Overhead más alto: Requiere más procesamiento para localizar bloques de memoria adecuados y manejar la liberación de memoria.

b)
Información necesaria para administrar memoria
El sistema operativo debe disponer de:

Tabla de particiones:
Indica qué particiones están libres y cuáles están asignadas.

Tamaño de particiones (fijas o dinámicas):
En el caso de particiones dinámicas, el tamaño puede variar según los procesos.

Ubicación de cada partición:
Para asociar direcciones físicas con procesos.

Estado de las particiones:
Libre u ocupado, con el proceso asignado.

Algoritmo de asignación:
Estrategias como first fit, best fit, o worst fit para ubicar procesos en la memoria.

3) 
1. Particiones de Igual Tamaño
Ventajas:

Simplicidad en la gestión:
Fácil de implementar, ya que no se necesita considerar el tamaño de los procesos para 
decidir en qué partición ubicarlos.

Bajo overhead:
Menor procesamiento para la asignación, ya que todas las particiones son iguales y no 
se requiere buscar un tamaño adecuado.

Balance de carga uniforme:
Ideal para sistemas donde los procesos tienen tamaños similares, garantizando un uso 
equitativo de las particiones.

Desventajas:
Fragmentación interna:
Si el proceso es más pequeño que la partición, el espacio sobrante dentro de la partición se desperdicia.

Falta de flexibilidad:
Procesos más grandes que el tamaño de la partición no pueden ejecutarse, incluso si hay suficiente memoria disponible en total.

Ineficiencia con procesos de tamaños variados:
Procesos muy pequeños desperdician memoria, y procesos muy grandes no pueden ser admitidos.

2. Particiones de Diferente Tamaño
Ventajas:
Mayor flexibilidad:
Permite asignar procesos de diferentes tamaños a particiones que se ajusten mejor a sus necesidades, reduciendo la fragmentación interna.

Mejor uso de la memoria:
Los procesos pequeños pueden utilizar particiones más pequeñas, dejando las particiones grandes disponibles para procesos que realmente las necesiten.

Adecuación para sistemas con procesos variados:
Ideal para entornos donde los tamaños de los procesos son heterogéneos.

Desventajas:
Complejidad en la gestión:
Requiere más lógica para decidir qué proceso se asigna a cada partición según su tamaño.

Fragmentación externa:
Puede haber particiones grandes libres pero inutilizables si no hay procesos que las llenen completamente.

Carga desigual:
Las particiones grandes pueden estar subutilizadas si hay pocos procesos grandes, mientras que las particiones pequeñas pueden estar sobrecargadas.

4)
Fragmentación Interna (Particiones Fijas):
Definición:
Ocurre cuando el tamaño del proceso es menor que el tamaño de la partición asignada.
El espacio no utilizado dentro de la partición asignada queda desperdiciado, ya que no puede ser utilizado por otros procesos.
Causa:
Las particiones tienen un tamaño fijo que no siempre coincide con el tamaño real de los procesos.

Fragmentación Externa (Particiones Dinámicas):
Definición:
Ocurre cuando la memoria tiene suficientes bloques libres para asignar a un proceso, pero estos bloques están dispersos y no forman un espacio contiguo.
Causa:
La asignación y liberación dinámica de memoria genera bloques libres pequeños dispersos, que no pueden ser utilizados para procesos que requieren más memoria.

El problema de la fragmentación externa puede ser subsanado utilizando una técnica conocida como compactación.
Solucion → compactacion → muy costosa
Compactacion
Definición:
Es un proceso que reorganiza la memoria para combinar los bloques libres dispersos en un único bloque contiguo grande.

Funcionamiento:
Los procesos que están en ejecución son trasladados a ubicaciones contiguas dentro de la memoria.
Se libera un gran bloque contiguo de memoria al final, eliminando los pequeños fragmentos dispersos.

Ventajas:
Permite asignar grandes bloques de memoria a procesos que lo requieren.
Maximiza el uso de la memoria disponible.

Desventajas:
Implica un overhead significativo, ya que mover procesos en memoria consume tiempo y recursos del sistema.
No elimina la fragmentación para siempre, ya que esta puede reaparecer con nuevas asignaciones y liberaciones.

Alternativas a la compactación:
Mejoras en los algoritmos de asignación:
Utilizar estrategias como Best Fit o Worst Fit para minimizar el desperdicio de memoria desde el inicio.

Segmentación y paginación:
Estas técnicas avanzadas reorganizan cómo se gestiona la memoria para reducir o eliminar el problema de fragmentación externa.

5)
Paginacion
• La memoria se divide en porciones de igual tamãno llamadas
marco
• El espacio de direcciones de los procesos se divide en
porciones de igual tamano denominadas paginas
• Tamano pagina = tamano marco = 512 bytes (generalmente)
• El SO mantiene una tabla de paginas para cada proceso, la
cual contiene el marco donde se encuentra cada p ́agina
• La paginaci ́on bajo demanda es una t ́ecnica eficiente de
manejar esta estrategia → Thrashing

 Paginación
La paginación es una técnica de asignación de memoria que divide tanto la memoria principal como los procesos en bloques de tamaño fijo llamados páginas 
(en la memoria lógica) y marcos de página (en la memoria física). A continuación, se detalla cómo funciona este método y lo que implica su implementación.

(a) ¿Cómo trabaja este método de asignación de memoria?
División en bloques:
La memoria lógica de cada proceso se divide en bloques llamados páginas de un tamaño fijo.
La memoria física (RAM) se divide en bloques de tamaño igual llamados marcos de página.

Asignación de páginas a marcos:
Las páginas de los procesos se cargan en los marcos disponibles en la memoria física. No es necesario que las páginas estén contiguas, ya que el sistema operativo 
mantiene un registro de qué marco contiene cada página.

Traducción de direcciones:
Cuando un programa accede a una dirección de memoria lógica, el sistema operativo la traduce en una dirección física mediante una tabla de páginas.

Ventajas:
Elimina la fragmentación externa, ya que cualquier página puede ser cargada en cualquier marco disponible.
Permite usar la memoria de manera más eficiente al dividir los procesos en bloques manejables.

Desventajas:
Introduce un overhead adicional para mantener y acceder a las tablas de páginas.
Puede generar fragmentación interna si el último bloque de un proceso no utiliza completamente una página.

(b) Estructuras adicionales necesarias en el sistema operativo
Tabla de Páginas (Page Table):
Asocia cada página lógica del proceso con un marco físico en la memoria.
Contiene información como:
Número del marco asociado a cada página.
Bits de control (por ejemplo, si la página está presente en memoria o ha sido modificada).

Registro Base de la Tabla de Páginas (Page Table Base Register, PTBR):
Almacena la dirección inicial de la tabla de páginas del proceso actual.

TLB (Translation Lookaside Buffer):
Una memoria caché que almacena las traducciones recientes de páginas lógicas a marcos físicos para acelerar el acceso.

Control de memoria virtual (si se usa):
Cuando la memoria física es insuficiente, las páginas no usadas recientemente se almacenan en el disco, y se necesita una estructura 
adicional para administrar estas páginas (por ejemplo, swap file).

d_ 
Fragmentación Interna
¿Es posible?
Sí, puede ocurrir.
¿Por qué ocurre?
El tamaño de una página es fijo, y no todos los procesos o bloques de datos ocupan exactamente un múltiplo de ese tamaño.
Esto deja espacio sin usar al final de la última página de un proceso.

Fragmentación Externa
¿Es posible?
No, la paginación elimina este tipo de fragmentación.
¿Por qué no ocurre?
En la paginación, los bloques de memoria física (marcos) son todos del mismo tamaño. Esto significa que cualquier página de 
un proceso puede colocarse en cualquier marco libre, sin necesidad de contigüidad.
Como resultado, no hay espacios libres inutilizables dispersos en la memoria.

6_

Similitudes: Ambos métodos trabajan con bloques de tamaño fijo, lo que simplifica la asignación de memoria, 
aunque pueden generar fragmentación interna.
Diferencias: La paginación es más flexible al permitir la asignación no contigua y eliminar la fragmentación externa, a 
costa de una mayor complejidad debido al uso de tablas de páginas. En cambio, las particiones fijas son más simples pero 
menos eficientes para manejar procesos de tamaños variados.

8) 
a_ Se necesitan 13 bits si fuera una direccion por byte. 3 bits para las 8 paginas y 10 bits para los 1024 bytes.
b_ Se necesitan 15 bits si fuera una direccion por byte. 5 bits para los 32 marcos y 10 bits para los 1024 bytes.

9) Segmentación
a) ¿Cómo trabaja este método de asignación de memoria?
La segmentación es un método de asignación de memoria que divide el espacio de direcciones de un proceso en segmentos lógicos de 
diferentes tamaños, cada uno representando una unidad funcional (como código, pila, datos, etc.).
En lugar de considerar la memoria como un bloque continuo, cada segmento se asigna de forma independiente en la memoria física.

Características:
Cada segmento tiene un tamaño variable.
Cada segmento se identifica mediante un número (número de segmento).
Las direcciones lógicas constan de dos componentes:
Número de segmento: Identifica el segmento.
Desplazamiento: Especifica la ubicación dentro del segmento.

b) ¿Qué estructuras adicionales debe poseer el SO para implementarlo?
Tabla de segmentos:
Cada proceso tiene una tabla de segmentos asociada. Contiene:
    La base del segmento (dirección física inicial del segmento).
    El límite del segmento (tamaño del segmento).
Permite convertir direcciones lógicas en físicas.

Manejador de excepciones:
Controla violaciones de acceso, como intentar acceder a un segmento inexistente o superar el límite de un segmento.

Unidad de gestión de memoria (MMU):
Traduce automáticamente las direcciones lógicas en físicas basándose en la tabla de segmentos.

c) Transformación de direcciones lógicas en físicas
La conversión de direcciones se realiza de la siguiente manera:

Dirección lógica: (Número de segmento, Desplazamiento)
Verificación del desplazamiento:
El desplazamiento debe ser menor que el límite del segmento (tamaño del segmento).
Traducción a dirección física:
Dirección física = Base del segmento + Desplazamiento.

Ejemplo gráfico:
Supongamos que un proceso tiene 3 segmentos:
Segmento 0 (Código): Base = 1000, Límite = 400.
Segmento 1 (Datos): Base = 2000, Límite = 300.
Segmento 2 (Pila): Base = 3000, Límite = 200.

Una dirección lógica (1, 150):

Se refiere al Segmento 1 (Datos).
Se verifica que 150 < 300 (límite del segmento).
Dirección física = 2000 (base) + 150 (desplazamiento) = 2150.

d) ¿Se puede producir fragmentación (interna y/o externa)?
Fragmentación interna:
No ocurre. Los segmentos se ajustan exactamente al tamaño necesario del proceso, sin desperdiciar memoria dentro del segmento.

Fragmentación externa:
Sí ocurre. Debido a que los segmentos son de tamaño variable, pueden quedar huecos entre ellos en la memoria física tras 
asignaciones y liberaciones.

10)
Similitudes entre segmentación y particiones dinámicas
Asignación de memoria variable:
Ambos métodos asignan bloques de memoria de tamaños variables según las necesidades del proceso.

Uso eficiente de la memoria:
Ambos intentan reducir el desperdicio al ajustar los bloques asignados al tamaño requerido por los procesos.

Fragmentación externa:
Ambos sufren de fragmentación externa porque los bloques liberados pueden no ser reutilizables debido a su tamaño o ubicación.

Ubicación de bloques:
En ambos métodos, los bloques de memoria asignados a un proceso pueden estar en diferentes ubicaciones físicas en la memoria.

Necesidad de estructura de control:
Ambos requieren una estructura de datos para rastrear los bloques asignados y los espacios libres.

La segmentación es más adecuada para sistemas que necesitan organizar la memoria según las necesidades lógicas del programa 
(como separar código, datos y pila).
Las particiones dinámicas son más simples, pero sufren más de fragmentación interna en comparación con la segmentación.

11)
Paginación: Divide la memoria de manera uniforme (tamaño fijo). Es más simple y eficiente, pero puede generar desperdicio 
dentro de las páginas.
Segmentación: Divide la memoria de manera lógica (tamaño variable). Es más adecuada para sistemas complejos, pero enfrenta 
problemas de fragmentación externa.
Ver imagen (ejercicio11.png).

13)
Beneficios del esquema de memoria virtual

Ejecución de programas más grandes que la memoria física:
La memoria virtual permite que los procesos usen más espacio de memoria que el disponible físicamente al utilizar 
almacenamiento secundario (disco) como extensión de la memoria principal.

Mejor utilización de la memoria física:
Los procesos cargan solo las partes necesarias en memoria, dejando espacio para otros procesos y reduciendo el desperdicio.

Aislamiento de procesos:
Cada proceso tiene su propio espacio de direcciones virtual, evitando que interfieran entre sí.

Flexibilidad en la asignación:
No se requiere que los procesos estén en bloques contiguos de memoria física, lo que simplifica la gestión y evita problemas de fragmentación externa.

Facilidad para compartir memoria:
Diferentes procesos pueden compartir secciones específicas de memoria virtual, como bibliotecas.

b) ¿En qué se debe apoyar el SO para su implementación?

Unidad de gestión de memoria (MMU):
Hardware que traduce direcciones virtuales a físicas y gestiona las tablas de páginas.

Tablas de páginas:
Estructuras que contienen la correspondencia entre páginas virtuales y marcos de memoria física.

Almacenamiento secundario:
Un espacio en el disco (habitualmente llamado archivo de paginación o swap) para almacenar las páginas que no están en 
memoria física.

Algoritmos de reemplazo de páginas:
Deciden qué páginas deben trasladarse al disco cuando la memoria física está llena. Ejemplo: FIFO, LRU (Least Recently Used).

Interrupciones:
El sistema operativo maneja interrupciones de falta de página (page faults) cuando un proceso accede a una página que no 
está en memoria.

c) Información adicional en tablas de páginas (Paginación por demanda)
Además del marco físico donde se encuentra la página, las tablas de páginas deben incluir:

Bit de presencia/ausencia:
Indica si la página está actualmente en la memoria física o en el almacenamiento secundario.
Razón: Permite saber si un acceso genera un page fault.

Bit de modificación (dirty bit):
Indica si la página ha sido modificada desde que fue cargada en memoria.
Razón: Optimiza la escritura en disco, escribiendo solo las páginas que han sido modificadas.

Bit de acceso:
Indica si la página ha sido accedida recientemente.
Razón: Es útil para implementar algoritmos de reemplazo de páginas como LRU.

Información de protección:
Define los permisos de acceso (lectura, escritura, ejecución).
Razón: Garantiza la seguridad y evita accesos no autorizados.

Dirección del disco:
Ubicación en el almacenamiento secundario donde está almacenada la página.
Razón: Permite al SO recuperar la página cuando es necesario cargarla a memoria.

La memoria virtual permite una gestión eficiente y flexible de los recursos de memoria, pero su implementación requiere 
un soporte robusto del hardware y del sistema operativo, especialmente cuando se usa paginación por demanda para 
minimizar la carga inicial de los procesos en memoria física.


14. Fallos de Página (Page Faults)
a) ¿Cuándo se producen?
Un fallo de página ocurre cuando un proceso intenta acceder a una página que no está cargada en la memoria física. Esto puede 
suceder porque:
La página está en el almacenamiento secundario (swap o archivo de paginación) y necesita ser cargada en memoria.
El proceso solicita por primera vez una página que forma parte de su espacio virtual pero que aún no ha sido referenciada.

b) ¿Quién es responsable de detectar un fallo de página?
El hardware del sistema (específicamente la Unidad de Gestión de Memoria, MMU) es responsable de detectar el fallo de página.
La MMU, al intentar traducir una dirección virtual a física, verifica si la página está presente en la memoria física usando 
el bit de presencia/ausencia en la tabla de páginas.
Si la página no está presente, genera una interrupción que es manejada por el sistema operativo (SO).

c) Acciones que emprende el SO cuando se produce un fallo de página
Cuando ocurre un fallo de página, el SO ejecuta los siguientes pasos:

Pausar el proceso:
Detiene la ejecución del proceso que generó el fallo de página.

Determinar la ubicación de la página faltante:
Usa la información de la tabla de páginas para identificar si la página está en el almacenamiento secundario o si se trata de una 
referencia no válida (error de segmentación).

Asignar un marco en la memoria física:
Si no hay marcos disponibles, el SO ejecuta un algoritmo de reemplazo de páginas (como LRU o FIFO) para liberar espacio 
seleccionando una página existente.

Guardar la página reemplazada (si aplica):
Si la página seleccionada para ser reemplazada ha sido modificada (dirty bit activado), se escribe en el disco antes de liberarla.

Cargar la página faltante:
El SO copia la página requerida desde el almacenamiento secundario al marco de memoria recién asignado.

Actualizar la tabla de páginas:
Modifica la entrada correspondiente en la tabla de páginas para reflejar la nueva ubicación de la página en la memoria física y 
activa el bit de presencia.

Reanudar el proceso:
Una vez completada la carga, el proceso continúa su ejecución desde donde se interrumpió.
 
15)

16)

17)

18)

19)

20)

a) Clasificación de los algoritmos según la tasa de fallos de página
De peor a mejor, considerando un escenario típico:

FIFO (First-In, First-Out): Este algoritmo simplemente reemplaza la página que llegó primero sin considerar su uso reciente. 
Puede sufrir del anomalía de Belady, lo que significa que aumentar los marcos de memoria puede incrementar los fallos de página.

Segunda Oportunidad (Second-Chance): Mejora a FIFO al verificar si la página fue utilizada recientemente. Reduce fallos comparado
con FIFO, pero aún no es tan eficiente como los otros.

LRU (Least Recently Used): Selecciona la página que no ha sido usada durante más tiempo, lo que generalmente se acerca al 
comportamiento óptimo.

OPT (Óptimo): Es el mejor algoritmo teórico, ya que selecciona la página que no será utilizada por más tiempo en el futuro. Sin 
embargo, no es práctico porque requiere conocimiento perfecto del futuro.

b) Análisis y funcionamiento
1. FIFO (First-In, First-Out):
Funcionamiento: Mantiene una cola con las páginas en orden de llegada. Cuando se requiere reemplazo, elimina la página en el frente 
de la cola.
Implementación:
Utilizar una cola circular para administrar las páginas.
Insertar nuevas páginas en la parte trasera y eliminar desde el frente.
Desventaja: No considera si las páginas se usan frecuentemente.

2. Segunda Oportunidad (Second-Chance):
Funcionamiento: Igual a FIFO, pero verifica un bit de referencia (R). Si R = 1, la página tiene una "segunda oportunidad" y se mueve al final de la cola.
Implementación:
Mantener un bit de referencia para cada página.
Cuando se debe reemplazar:
Si R = 0: reemplazar la página.
Si R = 1: poner la página al final de la cola y resetear R a 0.
Ventaja: Mejora a FIFO al evitar reemplazar páginas usadas recientemente.

3. LRU (Least Recently Used):
Funcionamiento: Reemplaza la página que no ha sido usada durante más tiempo.
Implementación:
Usar una lista ordenada o una pila para rastrear el acceso a las páginas.
Alternativamente, usar una matriz o hardware especializado para medir intervalos de tiempo desde el último uso.
Ventaja: Es más eficiente que FIFO y Segunda Oportunidad al basarse en el uso reciente.

4. OPT (Óptimo):
Funcionamiento: Reemplaza la página que no será usada durante más tiempo en el futuro.
Implementación:
Simular el acceso futuro con base en el patrón de referencia.
Identificar cuál página tiene el mayor tiempo antes de ser usada nuevamente.
Desventaja: Imposible de implementar en sistemas reales porque requiere conocimiento perfecto del futuro.

c) Acciones del sistema operativo ante páginas modificadas
Cuando una página a ser reemplazada está modificada (bit de modificación o dirty bit está activo):

Escribir la página en disco:
El contenido de la página debe escribirse en su ubicación de respaldo en disco (por ejemplo, un archivo de respaldo o espacio 
de intercambio).
Esto garantiza que los cambios realizados en memoria no se pierdan.

Actualizar estructuras de datos:
Marcar el marco de la página como disponible en la tabla de marcos.
Actualizar las tablas de páginas correspondientes para reflejar que la página ya no está en memoria.

Carga de la nueva página:
Leer la nueva página del disco al marco liberado.
Actualizar las estructuras de datos, incluyendo las tablas de páginas y bits de control.

Optimización:
Algunas estrategias, como escribir páginas modificadas en disco de manera anticipada (write-back cache), pueden reducir 
la latencia del reemplazo.

21)
a) Políticas de reemplazo
1. Reemplazo Local
Descripción:
El sistema operativo solo considera las páginas que pertenecen al proceso que causó el fallo de página.
Cada proceso tiene asignados un conjunto fijo de marcos, y las páginas víctimas se seleccionan exclusivamente de ese conjunto.
Ventajas:
Aislamiento: Evita que un proceso afecte el desempeño de otros.
Controlado: Permite al administrador asignar marcos según prioridades.
Desventajas:
Ineficiencia: Si un proceso tiene marcos sin usar, no puede compartirlos con otros procesos que los necesiten.

2. Reemplazo Global
Descripción:
El sistema operativo considera todas las páginas en la memoria principal, independientemente de a qué proceso pertenecen.
La página víctima puede pertenecer a cualquier proceso activo.
Ventajas:
Flexibilidad: Mejora la utilización de la memoria al permitir que los procesos compartan marcos según la demanda.
Mejor rendimiento: Puede reducir fallos de página globales.
Desventajas:
Interferencia: Un proceso puede afectar negativamente a otros si consume demasiados marcos.

b) ¿Es posible utilizar “Asignación Fija” junto con “Reemplazo Global”?

No es coherente combinar asignación fija de marcos con reemplazo global, debido a sus principios opuestos:
Asignación Fija:
Cada proceso tiene un número predeterminado de marcos que no varía, sin importar las necesidades actuales de memoria.
Incompatible con reemplazo global, ya que este permite que un proceso utilice marcos asignados a otros procesos.

Reemplazo Global:
Permite que los procesos compartan marcos dinámicamente según la demanda.
Contradice el principio de asignación fija, que restringe los marcos a cada proceso.

Justificación:
El problema fundamental es que la asignación fija asegura que cada proceso tiene un número reservado de marcos, mientras que el 
reemplazo global busca optimizar el uso de marcos disponibles en todo el sistema.
Por lo tanto, para utilizar reemplazo global, generalmente se requiere una política de asignación dinámica, donde los marcos 
pueden redistribuirse entre los procesos según las necesidades.




