1_
• Direccion Logica:
• Es una direccion que enmascara o abstrae una direccion fısica
• Referencia a una localidad en memoria
• Se la debe traducir a una direccion fısica

• Direccion Fısica:
• Es la direccion real. Es con la que se accede efectivamente a
memoria
• Representa la direccion absoluta en memoria principal

La CPU trabaja con direcciones logicas. Para acceder a la
memoria se deben transformar en direcciones fısicas
El mapeo entre direcciones virtuales y fısicas se realiza
mediante hardware → MMU (Memory Management Unit)

2_ a)
• Particiones Fijas:• La memoria se divide en particiones o regiones de tama ̃no fijo
→ tama ̃nos iguales o diferentes
• Alojan un  ́unico proceso• Cada proceso se coloca en alguna partici ́on de acuerdo a alg ́un
criterio:• First Fit
• Best Fit
• Worst Fit
• Next Fit
• Particiones Din ́amicas:• Las particiones var ́ıan en tama ̃no y n ́umero
• Alojan un proceso cada una
• Cada partici ́on se genera en forma din ́amica del tama ̃no justo
que necesita el proceso

Particiones Fijas
Descripción:
La memoria principal se divide en un número fijo de particiones de tamaño predeterminado al iniciar el sistema.
Cada partición puede contener un proceso único.
Si el proceso necesita menos memoria que el tamaño de la partición, se desperdicia el espacio sobrante (fragmentación interna).

Ventajas:
Simple de implementar: Los tamaños de las particiones se establecen previamente.
Bajo overhead: La administración de la memoria es directa, ya que no se requieren cálculos complejos para ajustar las particiones.

Desventajas:
Fragmentación interna: Los procesos pequeños dejan partes de la memoria inutilizadas dentro de las particiones asignadas.
Falta de flexibilidad: Si un proceso es más grande que cualquier partición, no puede ser cargado, incluso si hay suficiente memoria disponible en total.

Particiones Dinámicas
Descripción:
La memoria principal se divide en particiones del tamaño exacto requerido por cada proceso en el momento de su asignación.
Se utiliza una técnica como First Fit, Best Fit, Next Fit o Worst Fit para encontrar un bloque de memoria adecuado.
A medida que los procesos terminan, se crean espacios vacíos que causan fragmentación externa.

Ventajas:
Mayor flexibilidad: Los procesos pueden ocupar exactamente la cantidad de memoria que necesitan, reduciendo la fragmentación interna.
Mejor uso de la memoria: Permite cargar procesos de diferentes tamaños siempre que haya espacio disponible.

Desventajas:
Fragmentación externa: Los bloques pequeños no utilizados entre particiones pueden volverse inutilizables con el tiempo.
Overhead más alto: Requiere más procesamiento para localizar bloques de memoria adecuados y manejar la liberación de memoria.

b)
Información necesaria para administrar memoria
El sistema operativo debe disponer de:

Tabla de particiones:
Indica qué particiones están libres y cuáles están asignadas.

Tamaño de particiones (fijas o dinámicas):
En el caso de particiones dinámicas, el tamaño puede variar según los procesos.

Ubicación de cada partición:
Para asociar direcciones físicas con procesos.

Estado de las particiones:
Libre u ocupado, con el proceso asignado.

Algoritmo de asignación:
Estrategias como first fit, best fit, o worst fit para ubicar procesos en la memoria.

3) 
1. Particiones de Igual Tamaño
Ventajas:

Simplicidad en la gestión:
Fácil de implementar, ya que no se necesita considerar el tamaño de los procesos para 
decidir en qué partición ubicarlos.

Bajo overhead:
Menor procesamiento para la asignación, ya que todas las particiones son iguales y no 
se requiere buscar un tamaño adecuado.

Balance de carga uniforme:
Ideal para sistemas donde los procesos tienen tamaños similares, garantizando un uso 
equitativo de las particiones.

Desventajas:
Fragmentación interna:
Si el proceso es más pequeño que la partición, el espacio sobrante dentro de la partición se desperdicia.

Falta de flexibilidad:
Procesos más grandes que el tamaño de la partición no pueden ejecutarse, incluso si hay suficiente memoria disponible en total.

Ineficiencia con procesos de tamaños variados:
Procesos muy pequeños desperdician memoria, y procesos muy grandes no pueden ser admitidos.

2. Particiones de Diferente Tamaño
Ventajas:
Mayor flexibilidad:
Permite asignar procesos de diferentes tamaños a particiones que se ajusten mejor a sus necesidades, reduciendo la fragmentación interna.

Mejor uso de la memoria:
Los procesos pequeños pueden utilizar particiones más pequeñas, dejando las particiones grandes disponibles para procesos que realmente las necesiten.

Adecuación para sistemas con procesos variados:
Ideal para entornos donde los tamaños de los procesos son heterogéneos.

Desventajas:
Complejidad en la gestión:
Requiere más lógica para decidir qué proceso se asigna a cada partición según su tamaño.

Fragmentación externa:
Puede haber particiones grandes libres pero inutilizables si no hay procesos que las llenen completamente.

Carga desigual:
Las particiones grandes pueden estar subutilizadas si hay pocos procesos grandes, mientras que las particiones pequeñas pueden estar sobrecargadas.

4)
Fragmentación Interna (Particiones Fijas):
Definición:
Ocurre cuando el tamaño del proceso es menor que el tamaño de la partición asignada.
El espacio no utilizado dentro de la partición asignada queda desperdiciado, ya que no puede ser utilizado por otros procesos.
Causa:
Las particiones tienen un tamaño fijo que no siempre coincide con el tamaño real de los procesos.

Fragmentación Externa (Particiones Dinámicas):
Definición:
Ocurre cuando la memoria tiene suficientes bloques libres para asignar a un proceso, pero estos bloques están dispersos y no forman un espacio contiguo.
Causa:
La asignación y liberación dinámica de memoria genera bloques libres pequeños dispersos, que no pueden ser utilizados para procesos que requieren más memoria.

El problema de la fragmentación externa puede ser subsanado utilizando una técnica conocida como compactación.
Solucion → compactacion → muy costosa
Compactacion
Definición:
Es un proceso que reorganiza la memoria para combinar los bloques libres dispersos en un único bloque contiguo grande.

Funcionamiento:
Los procesos que están en ejecución son trasladados a ubicaciones contiguas dentro de la memoria.
Se libera un gran bloque contiguo de memoria al final, eliminando los pequeños fragmentos dispersos.

Ventajas:
Permite asignar grandes bloques de memoria a procesos que lo requieren.
Maximiza el uso de la memoria disponible.

Desventajas:
Implica un overhead significativo, ya que mover procesos en memoria consume tiempo y recursos del sistema.
No elimina la fragmentación para siempre, ya que esta puede reaparecer con nuevas asignaciones y liberaciones.

Alternativas a la compactación:
Mejoras en los algoritmos de asignación:
Utilizar estrategias como Best Fit o Worst Fit para minimizar el desperdicio de memoria desde el inicio.

Segmentación y paginación:
Estas técnicas avanzadas reorganizan cómo se gestiona la memoria para reducir o eliminar el problema de fragmentación externa.

5)
Paginacion
• La memoria se divide en porciones de igual tamãno llamadas
marco
• El espacio de direcciones de los procesos se divide en
porciones de igual tamano denominadas paginas
• Tamano pagina = tamano marco = 512 bytes (generalmente)
• El SO mantiene una tabla de paginas para cada proceso, la
cual contiene el marco donde se encuentra cada p ́agina
• La paginaci ́on bajo demanda es una t ́ecnica eficiente de
manejar esta estrategia → Thrashing

 Paginación
La paginación es una técnica de asignación de memoria que divide tanto la memoria principal como los procesos en bloques de tamaño fijo llamados páginas 
(en la memoria lógica) y marcos de página (en la memoria física). A continuación, se detalla cómo funciona este método y lo que implica su implementación.

(a) ¿Cómo trabaja este método de asignación de memoria?
División en bloques:
La memoria lógica de cada proceso se divide en bloques llamados páginas de un tamaño fijo.
La memoria física (RAM) se divide en bloques de tamaño igual llamados marcos de página.

Asignación de páginas a marcos:
Las páginas de los procesos se cargan en los marcos disponibles en la memoria física. No es necesario que las páginas estén contiguas, ya que el sistema operativo 
mantiene un registro de qué marco contiene cada página.

Traducción de direcciones:
Cuando un programa accede a una dirección de memoria lógica, el sistema operativo la traduce en una dirección física mediante una tabla de páginas.

Ventajas:
Elimina la fragmentación externa, ya que cualquier página puede ser cargada en cualquier marco disponible.
Permite usar la memoria de manera más eficiente al dividir los procesos en bloques manejables.

Desventajas:
Introduce un overhead adicional para mantener y acceder a las tablas de páginas.
Puede generar fragmentación interna si el último bloque de un proceso no utiliza completamente una página.

(b) Estructuras adicionales necesarias en el sistema operativo
Tabla de Páginas (Page Table):
Asocia cada página lógica del proceso con un marco físico en la memoria.
Contiene información como:
Número del marco asociado a cada página.
Bits de control (por ejemplo, si la página está presente en memoria o ha sido modificada).

Registro Base de la Tabla de Páginas (Page Table Base Register, PTBR):
Almacena la dirección inicial de la tabla de páginas del proceso actual.

TLB (Translation Lookaside Buffer):
Una memoria caché que almacena las traducciones recientes de páginas lógicas a marcos físicos para acelerar el acceso.

Control de memoria virtual (si se usa):
Cuando la memoria física es insuficiente, las páginas no usadas recientemente se almacenan en el disco, y se necesita una estructura 
adicional para administrar estas páginas (por ejemplo, swap file).

d_ 
Fragmentación Interna
¿Es posible?
Sí, puede ocurrir.
¿Por qué ocurre?
El tamaño de una página es fijo, y no todos los procesos o bloques de datos ocupan exactamente un múltiplo de ese tamaño.
Esto deja espacio sin usar al final de la última página de un proceso.

Fragmentación Externa
¿Es posible?
No, la paginación elimina este tipo de fragmentación.
¿Por qué no ocurre?
En la paginación, los bloques de memoria física (marcos) son todos del mismo tamaño. Esto significa que cualquier página de 
un proceso puede colocarse en cualquier marco libre, sin necesidad de contigüidad.
Como resultado, no hay espacios libres inutilizables dispersos en la memoria.

6_

Similitudes: Ambos métodos trabajan con bloques de tamaño fijo, lo que simplifica la asignación de memoria, 
aunque pueden generar fragmentación interna.
Diferencias: La paginación es más flexible al permitir la asignación no contigua y eliminar la fragmentación externa, a 
costa de una mayor complejidad debido al uso de tablas de páginas. En cambio, las particiones fijas son más simples pero 
menos eficientes para manejar procesos de tamaños variados.

8) 
a_ Se necesitan 13 bits si fuera una direccion por byte. 3 bits para las 8 paginas y 10 bits para los 1024 bytes.
b_ Se necesitan 15 bits si fuera una direccion por byte. 5 bits para los 32 marcos y 10 bits para los 1024 bytes.

9) Segmentación
a) ¿Cómo trabaja este método de asignación de memoria?
La segmentación es un método de asignación de memoria que divide el espacio de direcciones de un proceso en segmentos lógicos de 
diferentes tamaños, cada uno representando una unidad funcional (como código, pila, datos, etc.).
En lugar de considerar la memoria como un bloque continuo, cada segmento se asigna de forma independiente en la memoria física.

Características:
Cada segmento tiene un tamaño variable.
Cada segmento se identifica mediante un número (número de segmento).
Las direcciones lógicas constan de dos componentes:
Número de segmento: Identifica el segmento.
Desplazamiento: Especifica la ubicación dentro del segmento.

b) ¿Qué estructuras adicionales debe poseer el SO para implementarlo?
Tabla de segmentos:
Cada proceso tiene una tabla de segmentos asociada. Contiene:
    La base del segmento (dirección física inicial del segmento).
    El límite del segmento (tamaño del segmento).
Permite convertir direcciones lógicas en físicas.

Manejador de excepciones:
Controla violaciones de acceso, como intentar acceder a un segmento inexistente o superar el límite de un segmento.

Unidad de gestión de memoria (MMU):
Traduce automáticamente las direcciones lógicas en físicas basándose en la tabla de segmentos.

c) Transformación de direcciones lógicas en físicas
La conversión de direcciones se realiza de la siguiente manera:

Dirección lógica: (Número de segmento, Desplazamiento)
Verificación del desplazamiento:
El desplazamiento debe ser menor que el límite del segmento (tamaño del segmento).
Traducción a dirección física:
Dirección física = Base del segmento + Desplazamiento.

Ejemplo gráfico:
Supongamos que un proceso tiene 3 segmentos:
Segmento 0 (Código): Base = 1000, Límite = 400.
Segmento 1 (Datos): Base = 2000, Límite = 300.
Segmento 2 (Pila): Base = 3000, Límite = 200.

Una dirección lógica (1, 150):

Se refiere al Segmento 1 (Datos).
Se verifica que 150 < 300 (límite del segmento).
Dirección física = 2000 (base) + 150 (desplazamiento) = 2150.

d) ¿Se puede producir fragmentación (interna y/o externa)?
Fragmentación interna:
No ocurre. Los segmentos se ajustan exactamente al tamaño necesario del proceso, sin desperdiciar memoria dentro del segmento.

Fragmentación externa:
Sí ocurre. Debido a que los segmentos son de tamaño variable, pueden quedar huecos entre ellos en la memoria física tras 
asignaciones y liberaciones.

10)
Similitudes entre segmentación y particiones dinámicas
Asignación de memoria variable:
Ambos métodos asignan bloques de memoria de tamaños variables según las necesidades del proceso.

Uso eficiente de la memoria:
Ambos intentan reducir el desperdicio al ajustar los bloques asignados al tamaño requerido por los procesos.

Fragmentación externa:
Ambos sufren de fragmentación externa porque los bloques liberados pueden no ser reutilizables debido a su tamaño o ubicación.

Ubicación de bloques:
En ambos métodos, los bloques de memoria asignados a un proceso pueden estar en diferentes ubicaciones físicas en la memoria.

Necesidad de estructura de control:
Ambos requieren una estructura de datos para rastrear los bloques asignados y los espacios libres.

La segmentación es más adecuada para sistemas que necesitan organizar la memoria según las necesidades lógicas del programa 
(como separar código, datos y pila).
Las particiones dinámicas son más simples, pero sufren más de fragmentación interna en comparación con la segmentación.

11)
Paginación: Divide la memoria de manera uniforme (tamaño fijo). Es más simple y eficiente, pero puede generar desperdicio 
dentro de las páginas.
Segmentación: Divide la memoria de manera lógica (tamaño variable). Es más adecuada para sistemas complejos, pero enfrenta 
problemas de fragmentación externa.
Ver imagen (ejercicio11.png).

13)
Beneficios del esquema de memoria virtual

Ejecución de programas más grandes que la memoria física:
La memoria virtual permite que los procesos usen más espacio de memoria que el disponible físicamente al utilizar 
almacenamiento secundario (disco) como extensión de la memoria principal.

Mejor utilización de la memoria física:
Los procesos cargan solo las partes necesarias en memoria, dejando espacio para otros procesos y reduciendo el desperdicio.

Aislamiento de procesos:
Cada proceso tiene su propio espacio de direcciones virtual, evitando que interfieran entre sí.

Flexibilidad en la asignación:
No se requiere que los procesos estén en bloques contiguos de memoria física, lo que simplifica la gestión y evita problemas de fragmentación externa.

Facilidad para compartir memoria:
Diferentes procesos pueden compartir secciones específicas de memoria virtual, como bibliotecas.

b) ¿En qué se debe apoyar el SO para su implementación?

Unidad de gestión de memoria (MMU):
Hardware que traduce direcciones virtuales a físicas y gestiona las tablas de páginas.

Tablas de páginas:
Estructuras que contienen la correspondencia entre páginas virtuales y marcos de memoria física.

Almacenamiento secundario:
Un espacio en el disco (habitualmente llamado archivo de paginación o swap) para almacenar las páginas que no están en 
memoria física.

Algoritmos de reemplazo de páginas:
Deciden qué páginas deben trasladarse al disco cuando la memoria física está llena. Ejemplo: FIFO, LRU (Least Recently Used).

Interrupciones:
El sistema operativo maneja interrupciones de falta de página (page faults) cuando un proceso accede a una página que no 
está en memoria.

c) Información adicional en tablas de páginas (Paginación por demanda)
Además del marco físico donde se encuentra la página, las tablas de páginas deben incluir:

Bit de presencia/ausencia:
Indica si la página está actualmente en la memoria física o en el almacenamiento secundario.
Razón: Permite saber si un acceso genera un page fault.

Bit de modificación (dirty bit):
Indica si la página ha sido modificada desde que fue cargada en memoria.
Razón: Optimiza la escritura en disco, escribiendo solo las páginas que han sido modificadas.

Bit de acceso:
Indica si la página ha sido accedida recientemente.
Razón: Es útil para implementar algoritmos de reemplazo de páginas como LRU.

Información de protección:
Define los permisos de acceso (lectura, escritura, ejecución).
Razón: Garantiza la seguridad y evita accesos no autorizados.

Dirección del disco:
Ubicación en el almacenamiento secundario donde está almacenada la página.
Razón: Permite al SO recuperar la página cuando es necesario cargarla a memoria.

La memoria virtual permite una gestión eficiente y flexible de los recursos de memoria, pero su implementación requiere 
un soporte robusto del hardware y del sistema operativo, especialmente cuando se usa paginación por demanda para 
minimizar la carga inicial de los procesos en memoria física.


14. Fallos de Página (Page Faults)
a) ¿Cuándo se producen?
Un fallo de página ocurre cuando un proceso intenta acceder a una página que no está cargada en la memoria física. Esto puede 
suceder porque:
La página está en el almacenamiento secundario (swap o archivo de paginación) y necesita ser cargada en memoria.
El proceso solicita por primera vez una página que forma parte de su espacio virtual pero que aún no ha sido referenciada.

b) ¿Quién es responsable de detectar un fallo de página?
El hardware del sistema (específicamente la Unidad de Gestión de Memoria, MMU) es responsable de detectar el fallo de página.
La MMU, al intentar traducir una dirección virtual a física, verifica si la página está presente en la memoria física usando 
el bit de presencia/ausencia en la tabla de páginas.
Si la página no está presente, genera una interrupción que es manejada por el sistema operativo (SO).

c) Acciones que emprende el SO cuando se produce un fallo de página
Cuando ocurre un fallo de página, el SO ejecuta los siguientes pasos:

Pausar el proceso:
Detiene la ejecución del proceso que generó el fallo de página.

Determinar la ubicación de la página faltante:
Usa la información de la tabla de páginas para identificar si la página está en el almacenamiento secundario o si se trata de una 
referencia no válida (error de segmentación).

Asignar un marco en la memoria física:
Si no hay marcos disponibles, el SO ejecuta un algoritmo de reemplazo de páginas (como LRU o FIFO) para liberar espacio 
seleccionando una página existente.

Guardar la página reemplazada (si aplica):
Si la página seleccionada para ser reemplazada ha sido modificada (dirty bit activado), se escribe en el disco antes de liberarla.

Cargar la página faltante:
El SO copia la página requerida desde el almacenamiento secundario al marco de memoria recién asignado.

Actualizar la tabla de páginas:
Modifica la entrada correspondiente en la tabla de páginas para reflejar la nueva ubicación de la página en la memoria física y 
activa el bit de presencia.

Reanudar el proceso:
Una vez completada la carga, el proceso continúa su ejecución desde donde se interrumpió.
 
15)

16)
La administración de tablas de páginas en sistemas operativos utiliza distintos enfoques para manejar la conversión de direcciones virtuales 
a físicas, optimizando el uso de la memoria y mejorando la eficiencia. Aquí se explican brevemente los enfoques mencionados:

1. Tablas de páginas de 1 nivel
En este esquema, cada proceso tiene una única tabla de páginas que contiene las direcciones físicas correspondientes a todas sus páginas virtuales.
Funcionamiento:
La dirección virtual se divide en dos partes:
Número de página virtual (VPN): Indica la entrada en la tabla de páginas.
Desplazamiento: Especifica la posición dentro de la página.
El sistema busca la entrada correspondiente en la tabla de páginas usando el VPN.
La dirección física se obtiene combinando la dirección base de la página física con el desplazamiento.
Ventajas:
Fácil de implementar.
Rápida para espacios de direcciones pequeñas.
Desventajas:
Consume mucha memoria si el espacio de direcciones es grande, ya que requiere una tabla grande que debe estar en memoria.

2. Tablas de páginas de 2 niveles
Este enfoque divide la tabla de páginas en dos niveles jerárquicos para reducir su tamaño en memoria.
Funcionamiento:
La dirección virtual se divide en tres partes:
Índice de la tabla de nivel superior: Apunta a una tabla secundaria.
Índice de la tabla de nivel inferior: Identifica la entrada específica en la tabla secundaria.
Desplazamiento: Especifica la posición dentro de la página.
El sistema accede primero a la tabla de nivel superior para localizar la tabla secundaria correspondiente.
Luego, busca en la tabla secundaria la dirección base de la página física.
Finalmente, combina la dirección base con el desplazamiento para obtener la dirección física.
Ventajas:
Reduce el tamaño de las tablas al cargar solo las necesarias.
Útil para direcciones virtuales grandes.
Desventajas:
Incrementa la complejidad y el número de accesos a memoria (dos niveles).

3. Tablas de páginas invertidas
Este enfoque almacena una sola tabla global para todo el sistema, en lugar de tener una tabla por proceso. Cada entrada mapea una página 
física a una página virtual
Funcionamiento:
La dirección virtual se divide en:
Número de página virtual (VPN): Identifica la página dentro del espacio virtual.
Desplazamiento: Especifica la posición dentro de la página.
Para encontrar una página, el sistema busca en la tabla de páginas invertida usando una combinación del VPN y el ID del proceso.
Si se encuentra una coincidencia, se obtiene la dirección base de la página física.
Combina la dirección base con el desplazamiento para obtener la dirección física.
Ventajas:
Menor uso de memoria, ya que la tabla es proporcional al número de páginas físicas.
Escalabilidad en sistemas con múltiples procesos.
Desventajas:
Las búsquedas en la tabla pueden ser lentas si no se utiliza un mecanismo eficiente, como un hash table.
Transformación de dirección virtual a física

En los tres esquemas, la dirección virtual se divide en componentes (índices y desplazamientos).
La tabla de páginas mapea las páginas virtuales a las físicas.
Se combinan los resultados para obtener la dirección física.
Cada enfoque busca equilibrar eficiencia, velocidad y uso de memoria según los requisitos del sistema.

18) LEER!!
Un tamanio de pagina pequenio tiene como:
    - Ventajas:
        - Menor fragmentacion interna. 
        - Mayor granuladidad -> permite un mejor uso de la memoria fisica or que se cargan partes mas pequenias de los programas, solo lo necesario.
        - Reduccion de desechos en programas pequenios -> Los programas pequenios ocupan menos paginas, minimizando el desperdicio de espacio.
    - Desventajas
        - Mayor tamanio de la tablas de paginas.
        - Mayor sobrecarga en el manejo del sistema -> mas cambios de contexto y mas E/S.
        - Mayor numero de fallos de pagina debido a que se necesitan cargar paginas con mas frecuencia por el menor tamanio de las paginas. 

Un tamanio de pagina grande tiene como: 
    - Ventajas:
        - Menor tamanio de la tabla de paginas.
        - Menor sobrecarga administrativa. 
        - Menor numero de fallo de paginas.
    - Desventajas:
        - Mayor fragmentacion interna.
        - Carga innecesaria de datos. 
        - Uso ineficiente de la memoria fisica -> si las paginas son demasiado grandes puede haber menos espacio disponible para otros programas o 
            procesos activos. 

19)
a_Asignacion Fija: a cada proceso se le asigna una cantidad
arbitraria de marco. A su vez para el reparto se puede usar:
• Reparto equitativo: se asigna la misma cantidad de marcos a
cada proceso → m div p
• Reparto proporcional: se asignan marco en base a la
necesidad que tiene cada proceso → Vp. m / Vt

• Asignacion dinamica: los procesos se van cargando en forma
dinamica de acuerdo a la cantidad de marcos que necesiten

b_ 
i) 40 marcos DIV 4 procesos = 10 10 marcos para cada proceso.

ii) 
Proceso 1:
Marcos=(15 / 63) × 40 = 9.52 → 10 (redondeo)

Proceso 2:
Marcos = (20 / 63) × 40 = 12.7 → 13 (redondeo)

Proceso 3:
Marcos = (20 / 63) × 40 = 12.7 → 13 (redondeo)
​
Proceso 4:
Marcos = (8 / 63 ) × 40 = 5.08 → 4 (redondeo ajustado)

c_ El reparto equitativo resulta mas eficiente, porque se ajusta a lo que
necesita cada proceso.

20)
a) Clasificación de los algoritmos según la tasa de fallos de página
De peor a mejor, considerando un escenario típico:

FIFO (First-In, First-Out): Este algoritmo simplemente reemplaza la página que llegó primero sin considerar su uso reciente. 
Puede sufrir del anomalía de Belady, lo que significa que aumentar los marcos de memoria puede incrementar los fallos de página.

Segunda Oportunidad (Second-Chance): Mejora a FIFO al verificar si la página fue utilizada recientemente. Reduce fallos comparado
con FIFO, pero aún no es tan eficiente como los otros.

LRU (Least Recently Used): Selecciona la página que no ha sido usada durante más tiempo, lo que generalmente se acerca al 
comportamiento óptimo.

OPT (Óptimo): Es el mejor algoritmo teórico, ya que selecciona la página que no será utilizada por más tiempo en el futuro. Sin 
embargo, no es práctico porque requiere conocimiento perfecto del futuro.

b) Análisis y funcionamiento
1. FIFO (First-In, First-Out):
Funcionamiento: Mantiene una cola con las páginas en orden de llegada. Cuando se requiere reemplazo, elimina la página en el frente 
de la cola.
Implementación:
Utilizar una cola circular para administrar las páginas.
Insertar nuevas páginas en la parte trasera y eliminar desde el frente.
Desventaja: No considera si las páginas se usan frecuentemente.

2. Segunda Oportunidad (Second-Chance):
Funcionamiento: Igual a FIFO, pero verifica un bit de referencia (R). Si R = 1, la página tiene una "segunda oportunidad" y se mueve al final de la cola.
Implementación:
Mantener un bit de referencia para cada página.
Cuando se debe reemplazar:
Si R = 0: reemplazar la página.
Si R = 1: poner la página al final de la cola y resetear R a 0.
Ventaja: Mejora a FIFO al evitar reemplazar páginas usadas recientemente.

3. LRU (Least Recently Used):
Funcionamiento: Reemplaza la página que no ha sido usada durante más tiempo.
Implementación:
Usar una lista ordenada o una pila para rastrear el acceso a las páginas.
Alternativamente, usar una matriz o hardware especializado para medir intervalos de tiempo desde el último uso.
Ventaja: Es más eficiente que FIFO y Segunda Oportunidad al basarse en el uso reciente.

4. OPT (Óptimo):
Funcionamiento: Reemplaza la página que no será usada durante más tiempo en el futuro.
Implementación:
Simular el acceso futuro con base en el patrón de referencia.
Identificar cuál página tiene el mayor tiempo antes de ser usada nuevamente.
Desventaja: Imposible de implementar en sistemas reales porque requiere conocimiento perfecto del futuro.

c) Acciones del sistema operativo ante páginas modificadas
Cuando una página a ser reemplazada está modificada (bit de modificación o dirty bit está activo):

Escribir la página en disco:
El contenido de la página debe escribirse en su ubicación de respaldo en disco (por ejemplo, un archivo de respaldo o espacio 
de intercambio).
Esto garantiza que los cambios realizados en memoria no se pierdan.

Actualizar estructuras de datos:
Marcar el marco de la página como disponible en la tabla de marcos.
Actualizar las tablas de páginas correspondientes para reflejar que la página ya no está en memoria.

Carga de la nueva página:
Leer la nueva página del disco al marco liberado.
Actualizar las estructuras de datos, incluyendo las tablas de páginas y bits de control.

Optimización:
Algunas estrategias, como escribir páginas modificadas en disco de manera anticipada (write-back cache), pueden reducir 
la latencia del reemplazo.

21)
a) Políticas de reemplazo
1. Reemplazo Local
Descripción:
El sistema operativo solo considera las páginas que pertenecen al proceso que causó el fallo de página.
Cada proceso tiene asignados un conjunto fijo de marcos, y las páginas víctimas se seleccionan exclusivamente de ese conjunto.
Ventajas:
Aislamiento: Evita que un proceso afecte el desempeño de otros.
Controlado: Permite al administrador asignar marcos según prioridades.
Desventajas:
Ineficiencia: Si un proceso tiene marcos sin usar, no puede compartirlos con otros procesos que los necesiten.

2. Reemplazo Global
Descripción:
El sistema operativo considera todas las páginas en la memoria principal, independientemente de a qué proceso pertenecen.
La página víctima puede pertenecer a cualquier proceso activo.
Ventajas:
Flexibilidad: Mejora la utilización de la memoria al permitir que los procesos compartan marcos según la demanda.
Mejor rendimiento: Puede reducir fallos de página globales.
Desventajas:
Interferencia: Un proceso puede afectar negativamente a otros si consume demasiados marcos.

b) ¿Es posible utilizar “Asignación Fija” junto con “Reemplazo Global”?

No es coherente combinar asignación fija de marcos con reemplazo global, debido a sus principios opuestos:
Asignación Fija:
Cada proceso tiene un número predeterminado de marcos que no varía, sin importar las necesidades actuales de memoria.
Incompatible con reemplazo global, ya que este permite que un proceso utilice marcos asignados a otros procesos.

Reemplazo Global:
Permite que los procesos compartan marcos dinámicamente según la demanda.
Contradice el principio de asignación fija, que restringe los marcos a cada proceso.

Justificación:
El problema fundamental es que la asignación fija asegura que cada proceso tiene un número reservado de marcos, mientras que el 
reemplazo global busca optimizar el uso de marcos disponibles en todo el sistema.
Por lo tanto, para utilizar reemplazo global, generalmente se requiere una política de asignación dinámica, donde los marcos 
pueden redistribuirse entre los procesos según las necesidades.

25)
a) ¿Qué es?
La hiperpaginación (o trashing) ocurre cuando un sistema operativo dedica una cantidad desproporcionada de tiempo a gestionar el intercambio de 
páginas entre la memoria principal y la secundaria (swap), en lugar de ejecutar procesos útiles. Esto degrada severamente el rendimiento del 
sistema, ya que el procesador pasa más tiempo esperando que las páginas sean cargadas que ejecutando instrucciones.

b) ¿Cuáles pueden ser los motivos que la causan?
Falta de memoria física suficiente:
Los procesos requieren más páginas de las que la memoria principal puede acomodar.
Tamaño inadecuado del conjunto de trabajo:
Si el sistema no asigna suficientes marcos de página a los procesos, estos necesitarán acceder frecuentemente al disco para cargar las páginas 
necesarias.

Alta concurrencia:
Demasiados procesos activos compitiendo por una cantidad limitada de memoria, lo que resulta en un aumento excesivo de fallos de página.

Mala configuración de los parámetros de paginación:
Una política de reemplazo de páginas ineficiente puede expulsar páginas que serán necesarias en el futuro inmediato.

Comportamiento no lineal de los procesos:
Procesos que acceden a grandes conjuntos de datos de forma irregular pueden causar una alta tasa de fallos de página.

c) ¿Cómo la detecta el SO?
El sistema operativo puede detectar la hiperpaginación monitoreando indicadores clave como:
Tasa de fallos de página:
Una tasa anormalmente alta de fallos de página indica que los procesos no encuentran sus páginas en memoria y están accediendo constantemente 
al disco.
Uso del procesador:
Si el uso del CPU es bajo y el tiempo de espera por E/S es alto, puede ser un síntoma de trashing.
Actividad del disco:
Un aumento en la actividad de lectura/escritura del disco (swap in y swap out) indica que el sistema está gastando más tiempo gestionando la 
memoria que ejecutando instrucciones.

d) Una vez que lo detecta, ¿qué acciones puede tomar el SO para eliminar este problema?
Reducir la carga de procesos:
Suspender o sacar procesos no esenciales de la memoria para liberar recursos.
Aumentar los marcos asignados a los procesos:
Incrementar la cantidad de marcos asignados al conjunto de trabajo de los procesos más demandantes.
Optimizar las políticas de reemplazo de páginas:
Utilizar algoritmos más eficientes como LRU (Least Recently Used) o Clock Algorithm para evitar reemplazar páginas que serán utilizadas pronto.
Aumentar la memoria física:
Si es posible, agregar más memoria al sistema para manejar mejor la carga.
Disminuir la concurrencia:
Limitar el número de procesos activos que compiten por memoria en un momento dado.
Ajustar la configuración del sistema:
Modificar los parámetros del administrador de memoria, como el tamaño del archivo de intercambio (swap), para adaptarse mejor a las necesidades 
de los procesos.
Asignar prioridad a procesos críticos:
Asignar más recursos a procesos de alta prioridad y relegar procesos secundarios al almacenamiento secundario.
La hiperpaginación es un problema crítico que refleja la incapacidad del sistema para gestionar adecuadamente los recursos de memoria, y las 
soluciones requieren equilibrar la carga de trabajo y optimizar las políticas de memoria del sistema operativo

26)
Análisis de las mediciones en un sistema con paginación por demanda
a) Uso de CPU del 13%, uso del dispositivo de paginación del 97%
¿Qué sucede?
El sistema está experimentando hiperpaginación (trashing). La mayoría del tiempo se dedica al manejo de páginas en lugar de ejecutar procesos útiles.
La alta actividad del dispositivo de paginación (97%) indica que los procesos no tienen suficientes marcos de memoria asignados y están 
constantemente accediendo al disco para cargar y descargar páginas.
¿Puede incrementarse el nivel de multiprogramación?
No. Incrementar el nivel de multiprogramación solo aumentaría la carga de memoria y empeoraría el problema de trashing, ya que habría aún más 
procesos compitiendo por los escasos marcos disponibles.
¿La paginación está siendo útil?
No, la paginación no está mejorando el rendimiento en este caso. Al contrario, está causando un cuello de botella debido a la falta de memoria física 
para manejar los requerimientos de los procesos.

b) Uso de CPU del 87%, uso del dispositivo de paginación del 3%
¿Qué sucede?
El sistema está funcionando de manera eficiente. La CPU está ocupada ejecutando procesos, y la baja actividad del dispositivo de paginación (3%) 
indica que los procesos encuentran la mayoría de sus páginas en memoria, reduciendo los fallos de página.
¿Puede incrementarse el nivel de multiprogramación?
Potencialmente sí. Como la carga de memoria no es alta (uso del dispositivo de paginación bajo), se podrían agregar más procesos sin impactar 
negativamente el rendimiento. Sin embargo, esto debe hacerse con precaución para no sobrecargar la memoria.
¿La paginación está siendo útil?
Sí, la paginación está funcionando correctamente, permitiendo a los procesos acceder eficientemente a la memoria sin generar problemas de trashing.

c) Uso de CPU del 13%, uso del dispositivo de paginación del 3%
¿Qué sucede?
El sistema está infrautilizado. El bajo uso de CPU (13%) sugiere que no hay suficientes procesos listos para ejecutarse.
El bajo uso del dispositivo de paginación (3%) indica que no hay problemas relacionados con la memoria.
¿Puede incrementarse el nivel de multiprogramación?
Sí. El sistema tiene recursos disponibles (tanto memoria como capacidad de CPU) que no están siendo utilizados. Incrementar el número de procesos 
podría mejorar el uso de la CPU.
¿La paginación está siendo útil?
Sí, aunque el bajo uso de memoria implica que la paginación no está siendo un factor crítico en este escenario. Aumentar el nivel de 
multiprogramación podría demostrar su utilidad.

27)
En este escenario, el bajo uso del procesador (20%) combinado con el alto uso del dispositivo de paginación (97.7%) sugiere que el sistema está 
experimentando hiperpaginación (trashing). La mayoría de los ciclos de CPU se desperdician esperando que las páginas necesarias sean cargadas 
desde el dispositivo de paginación.

A continuación, se analiza cada acción propuesta y su impacto en la utilización del procesador:

a) Instalar un procesador más rápido
Impacto:
No mejorará significativamente la utilización del procesador. El problema no es la velocidad del CPU, sino el tiempo que pasa esperando por 
operaciones de paginación. Un procesador más rápido solo estaría inactivo por más tiempo, esperando las mismas páginas.
Conclusión:
No es una solución adecuada.

b) Instalar un dispositivo de paginación mayor
Impacto:
Un dispositivo de paginación mayor podría tener un impacto positivo si también es más rápido (por ejemplo, un SSD en lugar de un HDD), 
reduciendo el tiempo de acceso a las páginas. Sin embargo, no elimina la causa raíz del problema: la falta de memoria física.
Conclusión:
Podría ser útil, pero no es la solución ideal, ya que no aborda directamente el problema subyacente.

c) Incrementar el grado de multiprogramación
Impacto:
Incrementar el grado de multiprogramación agregará más procesos que competirán por los marcos de memoria. Esto aumentará la tasa de fallos 
de página y empeorará la hiperpaginación.
Conclusión:
No es recomendable. De hecho, esta acción agravará el problema.

d) Instalar más memoria principal
Impacto:
Instalar más memoria principal permite al sistema asignar más marcos a los procesos activos, reduciendo la tasa de fallos de página y, por ende, 
el uso del dispositivo de paginación. Esto mejorará directamente la utilización del procesador al disminuir el tiempo que pasa esperando por las 
páginas necesarias.
Conclusión:
Es la mejor solución para este caso, ya que aborda la causa raíz del problema.

e) Decrementar el quantum para cada proceso
Impacto:
Reducir el quantum puede aumentar la frecuencia de cambio de contexto entre procesos, lo que incrementará las demandas de memoria y podría 
aumentar aún más los fallos de página.
Conclusión:
No es recomendable en este escenario, ya que podría empeorar el problema de paginación.

28)
