1)
a_ Proceso:
‚Ä¢ Programa en ejecucion
‚Ä¢ Los conceptos de tarea, job y proceso hacen referencia a lo
mismo
‚Ä¢ Segun su historial de ejecucion, los podemos clasificar en:
‚Ä¢ CPU Bound (ligados a la CPU)
‚Ä¢ I/O Bound (ligados a entrada/salida)
‚Ä¢ Es dinamico
‚Ä¢ Tiene program counter
‚Ä¢ Su ciclo de vida comprende desde que se lo ejecuta hasta que
termina

Programa:
‚Ä¢ Es estatico
‚Ä¢ No tiene program counter
‚Ä¢ Existe desde que se edita hasta que se borra

b_ Tiempos de los procesos
‚Ä¢ Retorno: tiempo que transcurre entre que el proceso llega al
sistema hasta que completa su ejecucion.
‚Ä¢ Espera: tiempo que el proceso se encuentra en el sistema
esperando.

c_ Promedios: tiempos promedio de los anteriores.

d_ Quantum (Q): medida que determina cuanto tiempo
podra usar el procesador cada proceso.

e_ Nonpreemptive: una vez que un proceso esta en estado de
ejecucion, continua hasta que termina o se bloquea por algun
evento (e.j. I/O)

Preemptive: el proceso en ejecucion puede ser interrumpido y
llevado a la cola de listos:
    ‚Ä¢ Mayor overhead pero mejor servicio
    ‚Ä¢ Un proceso no monopoliza el procesador

f_ Short term scheduler: determina que proceso pasara a
ejecutarse.
Medium term scheduler: realiza el swapping (intercambio)
entre el disco y la memoria cuando el SO lo determina (puede
disminuir el grado de multiprogramacion).
Long term scheduler: admite nuevos procesos a memoria
(controla el grado de multirpogramacion).

g_ El dispatcher se encarga de asignar el tiempo de CPU a los procesos y de cambiar
entre procesos (lo que llamamos context switching). En otras palabras, decide qu√© 
proceso debe ejecutarse en cada momento para asegurar un uso eficiente del procesador.

2)
i. top
Descripci√≥n: Muestra en tiempo real una lista de los procesos que se est√°n ejecutando en el sistema, 
ordenados por el uso de CPU.
Comando:
top

ii. htop
Descripci√≥n: Una versi√≥n mejorada de top con una interfaz m√°s amigable y funcionalidad ampliada.
Comando:
htop

iii. ps
Descripci√≥n: Muestra una instant√°nea de los procesos en ejecuci√≥n en el sistema.
Comando:
ps aux     # Lista todos los procesos en detalle
ps -ef     # Otra opci√≥n para mostrar todos los procesos

iv. pstree
Descripci√≥n: Muestra los procesos en ejecuci√≥n en una estructura jer√°rquica o de √°rbol.
Comando:
pstree

v. kill
Descripci√≥n: Env√≠a una se√±al a un proceso espec√≠fico, generalmente para terminarlo.
Comando:
kill 1234        # Env√≠a la se√±al de terminaci√≥n al proceso con PID 1234
kill -9 1234     # Env√≠a la se√±al forzada (KILL) al proceso con PID 1234

vi. pgrep
Descripci√≥n: Busca procesos en ejecuci√≥n por nombre y devuelve sus PIDs.
Comando:
pgrep nombre_proceso

vii. killall
Descripci√≥n: Termina todos los procesos que coincidan con un nombre espec√≠fico.
Comando:
killall nombre_proceso

viii. renice
Descripci√≥n: Cambia la prioridad de ejecuci√≥n de un proceso en ejecuci√≥n.
Comando:
renice -n 10 -p 1234   # Cambia la prioridad del proceso con PID 1234 a 10

ix. xkill
Descripci√≥n: Permite seleccionar una ventana gr√°fica para matar el proceso que la controla.
Comando:
xkill

x. atop
Descripci√≥n: Una herramienta avanzada de monitoreo que muestra informaci√≥n detallada de procesos 
y de los recursos de hardware (CPU, memoria, disco, red).
Comando:
atop

b_ 
i. Al final de la ejecucion del programa habran 8 lineas con la palabra Proceso.
ii. El n√∫mero de l√≠neas es el n√∫mero de procesos que han estado en ejecuci√≥n

c_
proceso 7
proceso 6
proceso 5
proceso 4 
proceso 3
proceso 2   
proceso 1
proceso 0
ii. Tendran valores distintos. Cambia el numero.

Se ejecuta proceso N 2 elevado a la c veces.

d_ i. 
Comunicaci√≥n entre procesos a trav√©s de pipes
Los pipes permiten la comunicaci√≥n entre procesos en sistemas operativos como Unix/Linux, 
funcionando como un canal unidireccional por el cual un proceso puede enviar datos a otro. 
Existen dos tipos de pipes:

Pipes an√≥nimos: Son temporales y sirven para la comunicaci√≥n entre procesos relacionados (por ejemplo, procesos padre-hijo).
Named pipes o FIFOs: Persisten en el sistema de archivos y permiten la comunicaci√≥n entre procesos no relacionados.
Los pipes permiten que un proceso escriba datos en un extremo y otro proceso los lea desde el otro extremo, 
actuando como un archivo temporal de lectura/escritura.

ii. ¬øC√≥mo se crea un pipe en C?
Para crear un pipe en C se utiliza la funci√≥n pipe(), que pertenece a la biblioteca est√°ndar <unistd.h>. 
Esta funci√≥n crea un pipe an√≥nimo y devuelve dos descriptores de archivo (file descriptors): uno para lectura y 
otro para escritura.

#include <stdio.h>
#include <unistd.h>

int main() {
    int fd[2];  // Array para almacenar los descriptores de archivo

    // Crea el pipe
    if (pipe(fd) == -1) {
        perror("Error al crear el pipe");
        return 1;
    }

    // Ahora `fd[0]` es el extremo de lectura y `fd[1]` es el extremo de escritura.
    // Para usarlo, un proceso puede escribir en `fd[1]` y otro puede leer de `fd[0]`.

    return 0;
}
iii. ¬øQu√© par√°metro es necesario para la creaci√≥n de un pipe?
La funci√≥n pipe() recibe un solo par√°metro:

int pipe(int pipefd[2]);
Par√°metro pipefd[2]
pipefd es un array de dos enteros que se utilizar√° para almacenar los descriptores de archivo:
pipefd[0] es el descriptor de lectura del pipe.
pipefd[1] es el descriptor de escritura del pipe.
Al crear el pipe, se establece esta pareja de descriptores, permitiendo que un proceso escriba datos en pipefd[1] y 
otro los lea desde pipefd[0].
Uso
Estos descriptores son utilizados en llamadas a funciones de lectura y escritura, como read() y write(), permitiendo 
que los datos fluyan del proceso que escribe al proceso que lee. Si el proceso intenta leer cuando no hay datos 
disponibles, se bloquear√° hasta que haya datos en el pipe. Igualmente, si el pipe est√° lleno, el proceso escritor 
se bloquear√° hasta que el proceso lector lea y deje espacio.

iv. ¬øQu√© tipo de comunicaci√≥n es posible con pipes?
Los pipes permiten comunicaci√≥n unidireccional entre procesos. Esto significa que los datos fluyen en una sola direcci√≥n:

Comunicaci√≥n unidireccional: En los pipes an√≥nimos, un proceso escribe datos en un extremo, y otro proceso 
los lee en el otro extremo. Si se necesita comunicaci√≥n bidireccional (en ambas direcciones), es necesario 
crear dos pipes: uno para enviar datos en una direcci√≥n y otro para la direcci√≥n opuesta.

Comunicaci√≥n entre procesos relacionados: Los pipes an√≥nimos solo pueden usarse entre procesos relacionados 
(por ejemplo, entre un proceso padre y su proceso hijo) porque ambos deben compartir el mismo pipe creado 
antes de la bifurcaci√≥n (uso de fork()).

Comunicaci√≥n entre procesos no relacionados: Esto es posible con named pipes o FIFOs, que permiten la 
comunicaci√≥n entre procesos que no tienen una relaci√≥n directa. Named pipes se crean con mkfifo y son 
visibles en el sistema de archivos.

Ejemplo pr√°ctico de comunicaci√≥n entre procesos en C
Aqu√≠ tienes un ejemplo simple de uso de pipe() y fork() para que el proceso padre env√≠e datos al proceso hijo:

#include <stdio.h>
#include <unistd.h>
#include <string.h>

int main() {
    int fd[2];
    char mensaje[] = "Hola desde el padre";
    char buffer[100];

    // Crear el pipe
    if (pipe(fd) == -1) {
        perror("Error al crear el pipe");
        return 1;
    }

    if (fork() == 0) {  // Proceso hijo
        close(fd[1]);    // Cerrar el extremo de escritura
        read(fd[0], buffer, sizeof(buffer));  // Leer el mensaje del padre
        printf("Hijo recibi√≥: %s\n", buffer);
        close(fd[0]);
    } else {             // Proceso padre
        close(fd[0]);    // Cerrar el extremo de lectura
        write(fd[1], mensaje, strlen(mensaje) + 1);  // Enviar mensaje al hijo
        close(fd[1]);
    }

    return 0;
}

3_ Los tiempos de retorno van a convenir que sean bajos para aquellos lotes de procesos
que necesitamos tener una respuesta rapida de lo que se este ejecutando en si mismo. Lo que son
CPU bound vamos a necesitar que el TR se lo mas bajo posible para que el termine calculo lo mas
rapido posible. En los I/O bound vamos a necesitar que el tiempo de espera sea lo mas bajo
posible, es el tiempo que el proceso que va a estar esperando cumplir su rafaga siguiente.

FCFS
‚Ä¢ First come first served
‚Ä¢ Cuando hay que elegir un proceso para ejecutar, se selecciona
el mas viejo
‚Ä¢ No favorece a ning ÃÅun tipo de procesos, pero en principio
prod ÃÅƒ±amos decir que los CPU Bound terminan al comenzar su
primer r ÃÅafaga, mientras que los I/O Bound no

SJF
‚Ä¢ Shortest Job First
‚Ä¢ Pol ÃÅƒ±tica nonpreemptive que selecciona el proceso con la r ÃÅafaga
m ÃÅas corto
‚Ä¢ Calculo basado en la ejecuci ÃÅon previa
‚Ä¢ Procesos cortos se colocan delante de procesos largos
‚Ä¢ Los procesos largos pueden sufrir starvation (inanicion)

Algoritmo RR
‚Ä¢ Round Robin
‚Ä¢ Politica basada en un reloj
‚Ä¢ Quantum (Q): medida que determina cuanto tiempo
podr ÃÅa usar el procesador cada proceso:
‚Ä¢ Pequenio: overhead de context switch
‚Ä¢ Cuando un proceso es expulsado de la CPU es colocado al
final de la Ready Queue y se selecciona otro (FIFO circular )

‚Ä¢ Existe un ‚Äúcontador‚Äù que indica las unidades de CPU en las
que el proceso se ejecuto. Cuando el mismo llega a 0 el
proceso es expulsado
‚Ä¢ El ‚Äúcontador‚Äù puede ser:
‚Ä¢ Global
‚Ä¢ Local ‚Üí PCB
‚Ä¢ Existen dos variantes con respecto al valor inicial del
‚Äúcontador‚Äù cuando un proceso es asignado a la CPU:
‚Ä¢ Timer Variable
‚Ä¢ Timer Fijo

Algoritmo RR - Timer Variable
‚Ä¢ El ‚Äúcontador‚Äù se inicializa en Q (contador := Q) cada vez que
un proceso es asignado a la CPU
‚Ä¢ Es el mas utilizado

Algoritmo RR - Timer Fijo
‚Ä¢ El ‚Äúcontador‚Äù se inicializa en Q cuando su valor es cero
‚Ä¢ if (contador == 0) contador = Q;
‚Ä¢ Se puede ver como un valor de Q compartido entre los
procesos

Timer Fijo
En esta variante, el quantum es el mismo para todos los procesos.
¬øD√≥nde deber√≠a residir el quantum?
El quantum puede residir en una estructura global del sistema operativo que gestione 
la planificaci√≥n de procesos.
Razones:
Todos los procesos utilizan el mismo quantum.
Mantenerlo centralizado asegura que cualquier cambio sea uniforme y consistente para 
todos los procesos.

2. Timer Variable
En esta variante, el quantum puede variar entre procesos (por ejemplo, seg√∫n su 
prioridad o tipo).
¬øD√≥nde deber√≠a residir el quantum?
En este caso, el quantum debe ser una propiedad de cada proceso.
Se puede almacenar como un campo en la estructura de datos que representa a un proceso 
(como un PCB, Process Control Block).
Razones:
Cada proceso puede tener un quantum distinto.
Al almacenarlo en el PCB, el planificador puede acceder r√°pidamente al quantum del 
proceso actual.
Permite flexibilidad para adaptarse a las necesidades espec√≠ficas de los procesos o 
pol√≠ticas del sistema.

e_
El sistema operativo debe mantener cierta informaci√≥n m√≠nima sobre cada 
proceso para administrarlo de manera adecuada. Esta informaci√≥n se almacena 
en una estructura de datos conocida como PCB (Process Control Block) o 
Bloque de Control de Proceso.

Informaci√≥n m√≠nima que el SO debe tener sobre un proceso:

Identificaci√≥n del proceso:
PID (Process Identifier): Un identificador √∫nico que distingue al proceso 
de los dem√°s.

Estado del proceso:
Estado actual del proceso (ej. en ejecuci√≥n, listo, bloqueado, terminado).

Contexto de CPU:
Valores de los registros de la CPU (contador de programa, registros 
generales, etc.) necesarios para retomar la ejecuci√≥n del proceso.

Informaci√≥n de planificaci√≥n:
Prioridad del proceso, colas de planificaci√≥n, y otros datos relevantes 
para la asignaci√≥n de CPU.

Informaci√≥n de memoria:
Detalles de la memoria asignada al proceso, como:
Direcci√≥n base y l√≠mite.

Informaci√≥n de las tablas de p√°ginas o segmentos (si utiliza paginaci√≥n o 
segmentaci√≥n).

Informaci√≥n de E/S:
Archivos abiertos, dispositivos asignados, y buffers de entrada/salida.

Informaci√≥n de estado:
Se√±ales recibidas.
Contadores de eventos.
Indicadores de errores.

Estructura de datos asociada: PCB
El PCB (Process Control Block) es la estructura de datos donde el SO 
almacena toda esta informaci√≥n. Cada proceso tiene su propio PCB y, en 
general, el PCB incluye:

Identificador del proceso (PID).
Estado del proceso.
Contador de programa (PC).
Registros de CPU.
Informaci√≥n de memoria (segmentos, tablas de p√°gina).
Lista de archivos abiertos.
Informaci√≥n de permisos y credenciales del proceso.

Ubicaci√≥n del PCB
El PCB suele almacenarse en una regi√≥n reservada de la memoria principal 
o en una tabla de procesos mantenida por el kernel. Esto garantiza un 
acceso r√°pido y eficiente al contexto de cada proceso.

El sistema operativo utiliza el PCB para:
Cambiar el contexto entre procesos (context switch).
Supervisar y controlar la ejecuci√≥n de procesos.
Manejar la comunicaci√≥n y sincronizaci√≥n entre procesos.

f_
‚Ä¢ CPU Bound (ligados a la CPU)
‚Ä¢ I/O Bound (ligados a entrada/salida)

Un proceso es CPU Bound si pasa la mayor parte de su tiempo utilizando la 
CPU para realizar c√°lculos intensivos, con pocas operaciones de 
entrada/salida.

Un proceso es I/O Bound si pasa la mayor parte de su tiempo esperando 
operaciones de entrada/salida, como leer o escribir en discos, recibir 
datos de redes, o interactuar con dispositivos externos.

g_
1. Nuevo (New)
Descripci√≥n:
El proceso est√° siendo creado.

2. Listo (Ready)
Descripci√≥n:
El proceso est√° preparado para ejecutarse, pero est√° esperando a que la 
CPU est√© disponible.

3. Ejecutando (Running)
Descripci√≥n:
El proceso est√° utilizando la CPU y se encuentra en ejecuci√≥n.

4. Bloqueado o Esperando (Blocked/Waiting)
Descripci√≥n:
El proceso est√° esperando que se complete una operaci√≥n espec√≠fica, como 
una entrada/salida o un evento externo.

5. Terminado (Terminated)
Descripci√≥n:
El proceso ha finalizado su ejecuci√≥n (normalmente porque complet√≥ su 
tarea o fue finalizado por el sistema o el usuario).

h_ Imagen explicacion practica 4, pagina 5.

i_ 
Transici√≥n	                        Scheduler Responsable
Nuevo ‚Üí Listo	                    Long-Term Scheduler
Listo ‚Üí Ejecutando	                Short-Term Scheduler
Ejecutando ‚Üí Listo	                Short-Term Scheduler
Ejecutando ‚Üí Bloqueado	            Short-Term Scheduler
Bloqueado ‚Üí Listo	                Short-Term Scheduler
Listo ‚Üî Suspendido	                Medium-Term Scheduler
Bloqueado ‚Üî Suspendido Bloqueado	Medium-Term Scheduler

6_ d) y e)
El valor del quantum debe ser cuidadosamente seleccionado seg√∫n las caracter√≠sticas y objetivos del sistema:
Sistemas interactivos ‚Üí Quantum peque√±o.
Sistemas de alto rendimiento o c√°lculo intensivo ‚Üí Quantum m√°s grande.
Un valor extremadamente peque√±o o extremadamente grande puede llevar a una p√©rdida significativa de eficiencia o de usabilidad, respectivamente.

7_ El algoritmo SRTF beneficia a los procesos interactivos o de entrada salida.

8_ 
Ventajas del algoritmo por prioridades:
Atiende procesos cr√≠ticos primero, √∫til en sistemas en tiempo real.
Flexible, se adapta a diferentes entornos seg√∫n la importancia de las tareas.
Mejora el rendimiento para procesos con deadlines estrictos.
Ideal para sistemas heterog√©neos donde no todas las tareas tienen la misma relevancia.

Cu√°ndo usarlo:
Sistemas en tiempo real.
Entornos multitarea con procesos de distinta criticidad.
Colas con prioridades naturales, como en impresoras o routers.

Cu√°ndo no es relevante:
Cargas homog√©neas donde todas las tareas son iguales en importancia.
Sistemas interactivos donde se necesita responder r√°pido a todos los procesos.
Cuando asignar prioridades es complejo o costoso.
Riesgo de starvation, dejando procesos de baja prioridad sin ejecutar.

 9_ 
(a) ¬øQu√© significa?
La inanici√≥n (o starvation) ocurre en sistemas de planificaci√≥n de procesos cuando un proceso espera indefinidamente para ser ejecutado porque otros procesos, 
con mayor prioridad o preferencia, siempre son seleccionados antes. Esto sucede especialmente en sistemas donde los recursos no se asignan equitativamente o 
donde hay una alta competencia entre procesos.

En t√©rminos simples, un proceso "hambriento" nunca llega a ejecutarse debido a pol√≠ticas de planificaci√≥n injustas o ineficaces.

(b) ¬øCu√°l/es de los algoritmos vistos puede provocarla?
SJF (Shortest Job First):
Puede causar inanici√≥n si hay una secuencia continua de procesos cortos que llegan al sistema, bloqueando procesos m√°s largos.

SRTF (Shortest Remaining Time First):
Similar al SJF, pero m√°s propenso a inanici√≥n porque los procesos largos pueden ser constantemente interrumpidos por procesos nuevos m√°s cortos.

Algoritmo de Prioridades:
La inanici√≥n ocurre si los procesos de baja prioridad nunca son seleccionados debido a la llegada constante de procesos con mayor prioridad.

(c) ¬øExiste alguna t√©cnica que evite la inanici√≥n para el/los algoritmos mencionados en (b)?
S√≠, existen t√©cnicas para evitar la inanici√≥n:

SJF/SRTF:
Utilizar una variante con un l√≠mite de espera m√°xima: Los procesos que han esperado demasiado tiempo reciben una "penalizaci√≥n inversa" y su prioridad aumenta 
con el tiempo, d√°ndoles finalmente la oportunidad de ejecutarse.

Algoritmo de Prioridades:
Implementar prioridad envejecida (aging): La prioridad de un proceso aumenta progresivamente a medida que espera en la cola. Esto asegura que incluso los procesos 
de baja prioridad eventualmente ser√°n seleccionados.

11_ 
En el caso de los procesos ligados a CPU, el SRTF puede perjudicarlos debido a que estos procesos suelen ser mas largos y son desplazados por los 
procesos mas cortos pudiendo generar inanicion. En el caso de los procesos ligados a E/S no los perjudicaria ya que estos suelen ser mas cortos y 
tiende a priorizarlos.

Por otro lado, el algoritmo de Round Robin para los procesos ligados a E/S puede perjudicarlos ya que realiza muchos cambios de contexto para 
operaciones de E/S, entrando en estado de espera para volver a recuperar la CPU y dejando tiempo del Quantum inutilizado. En el caso de los 
procesos ligados a CPU, estos requieren largos tiempos de CPU y son limitados por el tiempo del quantum, reduciendo la eficiencia de su ejecucion.

13_ Si, puede suceder. Cuando la cantidad de CPU de un proceso no sea multiplo de la cantidad de Quantum porque siempre van a sobrar tiempos de quantum 
sin utilizar.
Por ejemplo: con un q = 5 y un proceso cuyo CPU = 5, el proceso se ejecutaria una vuelta de quantum y no le sobraria ninguna unidad.

14_ Consultar.

15_ 
Para implementar un esquema de Colas Multinivel para los tipos de procesos descritos (Interactivos y Batch), el dise√±o del algoritmo 
de planificaci√≥n requiere la selecci√≥n de algoritmos apropiados para:
Administrar los procesos dentro de cada cola.
Seleccionar qu√© cola ejecutar cuando ambas tienen procesos listos. 

(a) Administraci√≥n de cada cola:
Cola de procesos interactivos:
Los procesos interactivos suelen ser sensibles al tiempo de respuesta, por lo que es ideal utilizar un algoritmo que minimice los tiempos
de espera y respuesta.
Sugerencia: Round-Robin (RR) con un quantum peque√±o, ya que proporciona tiempos de respuesta r√°pidos y permite que los procesos interactivos 
alternen r√°pidamente en la CPU.

Cola de procesos Batch:
Los procesos batch no suelen ser sensibles al tiempo de respuesta y buscan maximizar el uso eficiente de la CPU.
Sugerencia: First-Come, First-Served (FCFS), ya que es simple y asegura que los procesos se ejecuten en el orden en que llegaron. 
Alternativamente, Shortest Job Next (SJN) podr√≠a ser utilizado si se puede estimar la duraci√≥n de los procesos.

(b) Planificaci√≥n entre las dos colas:
Para determinar cu√°l cola debe ejecutarse en cada momento, se puede usar un algoritmo de planificaci√≥n basado en prioridades. Por ejemplo:

Planificaci√≥n con Prioridad Est√°tica:
La cola de procesos interactivos tendr√≠a mayor prioridad que la de procesos batch.
La CPU atender√≠a siempre a los procesos interactivos cuando est√©n listos.
La cola de procesos batch solo se ejecutar√≠a cuando no haya procesos interactivos.

Planificaci√≥n con Prioridad Din√°mica (Ajustable):
Se asignan prioridades que se ajustan din√°micamente seg√∫n ciertos criterios, como la espera acumulada en la cola batch. Esto 
puede evitar inanici√≥n en la cola de menor prioridad.

Planificaci√≥n por Tiempo Compartido:
Se asigna un porcentaje del tiempo de CPU a cada cola. Por ejemplo:
70% para la cola interactiva.
30% para la cola batch.

18_
En este caso, se busca penalizar a los procesos que consumen mucho tiempo de CPU, bas√°ndonos en un esquema que favorezca 
procesos con menor tiempo de ejecuci√≥n restante. Esto se asemeja al comportamiento del SJF (Shortest Job First), pero 
adaptado a colas multilevel con realimentaci√≥n.

Dise√±o propuesto:

Estructura de colas:
Implementar varias colas donde los procesos se asignen seg√∫n el tiempo de ejecuci√≥n acumulado o restante:
Cola 1: Procesos que han consumido poco tiempo de CPU (alta prioridad).
Cola 2: Procesos con tiempo de ejecuci√≥n moderado.
Cola 3: Procesos que han consumido mucho tiempo de CPU (baja prioridad).

Algoritmo para cada cola:
Cola 1: Round-Robin con un quantum peque√±o para minimizar el tiempo de respuesta de procesos cortos.
Cola 2: Round-Robin con un quantum m√°s grande, equilibrando tiempo de espera y uso de CPU.
Cola 3: FCFS (First-Come, First-Served) para simplificar la planificaci√≥n de procesos largos.

Realimentaci√≥n entre colas:
Los procesos migran din√°micamente entre colas bas√°ndose en el tiempo de CPU consumido:
Cuando un proceso en Cola 1 consume m√°s tiempo que un umbral definido, pasa a Cola 2.
Lo mismo ocurre para el paso de Cola 2 a Cola 3.
Para evitar inanici√≥n, se aplica envejecimiento:
Los procesos en Cola 3 que esperan demasiado tiempo pueden ascender temporalmente a Cola 2 y luego a Cola 1, 
si contin√∫an esperando sin ser ejecutados.

Algoritmo para administrar las colas:
Utilizar prioridad est√°tica:
Cola 1 tiene mayor prioridad que Cola 2.
Cola 2 tiene mayor prioridad que Cola 3.
Aplicar envejecimiento din√°mico para permitir que procesos de colas inferiores obtengan CPU si han esperado demasiado.

19_

20_
Estrategias de administraci√≥n:

(a) Prioridad determinada est√°ticamente con el m√©todo del m√°s corto primero (SJF):
C√≥mo funciona:
Asigna mayor prioridad a los trabajos que tienen menor tiempo de ejecuci√≥n estimado, de manera est√°tica (no cambia durante la ejecuci√≥n del proceso).
Beneficia a:

Cortos acotados por CPU:
Estos trabajos tienen prioridad m√°xima, ya que requieren poco tiempo de CPU.
Se ejecutan r√°pidamente, reduciendo el tiempo promedio de espera y respuesta.

Cortos acotados por E/S:
Estos trabajos tambi√©n pueden beneficiarse, ya que suelen tener tiempos de CPU peque√±os y son atendidos r√°pidamente.
Sin embargo, el beneficio es limitado si las operaciones de E/S introducen tiempos de espera.
Desventajas:
Los procesos largos (CPU o E/S) tienden a sufrir starvation si siempre hay procesos cortos disponibles.

(b) Prioridad din√°mica inversamente proporcional al tiempo transcurrido desde la √∫ltima operaci√≥n de E/S:
C√≥mo funciona:
Aumenta din√°micamente la prioridad de los procesos en funci√≥n de cu√°nto tiempo ha pasado desde su √∫ltima operaci√≥n de E/S.
Procesos que dependen mucho de E/S tienen mayor prioridad para aprovechar su disponibilidad de CPU y evitar bloqueos por espera de dispositivos.

Beneficia a:
Cortos acotados por E/S:
Estos procesos obtienen una alta prioridad r√°pidamente debido a la frecuencia de sus operaciones de E/S.
Maximiza el uso eficiente de la CPU mientras minimiza los tiempos de espera para E/S.

Largos acotados por E/S:
Tambi√©n se benefician al mantener alta prioridad por sus frecuentes operaciones de E/S.
Sin embargo, los beneficios pueden ser limitados si la duraci√≥n total del proceso sigue siendo larga.

Desventajas:
Cortos acotados por CPU y largos acotados por CPU pueden ser relegados, ya que no realizan operaciones de E/S con frecuencia, 
perdiendo prioridad.


21_ 
El comportamiento del algoritmo Round-Robin se asemeja al de FIFO (First In, First Out) cuando el quantum 
ùëû se incrementa sin l√≠mite debido a c√≥mo se manejan las tareas en ambas estrategias:

Round-Robin con quantum limitado
En Round-Robin, las tareas se dividen en peque√±os bloques de tiempo definidos por el quantum (q).
Cada tarea se ejecuta por q unidades de tiempo o hasta que finaliza, lo que ocurra primero.
Si una tarea no termina en su quantum asignado, se coloca al final de la cola y espera su turno de nuevo.
Este enfoque da la apariencia de "turnos" cortos para las tareas, logrando una ejecuci√≥n equitativa.

Round-Robin con quantum grande
Si el valor del quantum aumenta significativamente (hasta llegar a ser mayor que el tiempo necesario para completar la mayor√≠a de las tareas), 
cada tarea pr√°cticamente se ejecutar√° en su totalidad antes de ceder el CPU.
Esto elimina el efecto de "interrupciones frecuentes" de Round-Robin, y las tareas se ejecutan en el orden en que llegaron a la cola, como en FIFO.

FIFO
FIFO simplemente ejecuta las tareas en el orden de llegada, permitiendo que cada tarea termine completamente antes de pasar a la siguiente.
No hay interrupciones ni cambios de contexto, lo que es similar al comportamiento de Round-Robin con 
ùëû extremadamente grande.

Conclusi√≥n
Cuando q tiende a infinito en Round-Robin:
Cada tarea recibe suficiente tiempo para completarse sin ser interrumpida.
La CPU sigue atendiendo las tareas en el orden en que llegaron, lo cual es el principio b√°sico de FIFO.
Por eso, al aumentar q sin l√≠mite, Round-Robin se degrada a FIFO, perdiendo las ventajas de equidad y tiempos de respuesta predecibles que caracterizan 
a Round-Robin con un quantum razonable.

22_ 
(a) ¬øCon cu√°l/es de estas clasificaciones se asocian las PCs de escritorio habituales?
Las PCs de escritorio habituales suelen asociarse con las siguientes clasificaciones:

Homog√©neos:
Los procesadores en una PC t√≠pica (como en sistemas multi-core) suelen ser id√©nticos y tienen las mismas capacidades f√≠sicas y de procesamiento.
Esto significa que no hay un procesador con ventajas f√≠sicas sobre los dem√°s.

Multiprocesador fuertemente acoplado:
En una PC moderna, los n√∫cleos del procesador comparten una memoria principal y operan bajo el control de un √∫nico sistema operativo.
Esto es t√≠pico en arquitecturas multi-core o CPU con m√∫ltiples hilos (threads).

Procesadores especializados (en algunos casos):
Muchas PCs incluyen coprocesadores o unidades especializadas, como una GPU (procesador gr√°fico), procesadores de IA, o procesadores criptogr√°ficos, que 
trabajan bajo el control de la CPU principal.

(b) ¬øQu√© significa que la asignaci√≥n de procesos se realice de manera sim√©trica?
La asignaci√≥n sim√©trica de procesos se refiere al modelo de Simmetric Multiprocessing (SMP), donde todos los procesadores tienen acceso equitativo a la 
memoria y recursos del sistema, y cada uno puede ejecutar cualquier proceso o tarea sin restricciones espec√≠ficas.
No hay distinci√≥n entre procesadores; todos tienen el mismo rol y responsabilidades.
El sistema operativo distribuye las tareas de forma balanceada entre los procesadores para optimizar el rendimiento.
Ejemplo: Si una tarea est√° en espera y hay un procesador libre, cualquier procesador puede tomarla.
Ventajas:
Mejora la eficiencia del sistema.
Proporciona tolerancia a fallos, ya que si un procesador falla, otro puede asumir su trabajo.

(c) ¬øQu√© significa que se trabaje bajo un esquema Maestro/Esclavo?
En un esquema Maestro/Esclavo, uno de los procesadores (el Maestro) asume un rol central de control, mientras que los dem√°s (los Esclavos) realizan tareas 
espec√≠ficas asignadas por el Maestro.
El Maestro: Gestiona la planificaci√≥n, distribuci√≥n de tareas, y supervisi√≥n del sistema.
Los Esclavos: Se limitan a ejecutar las tareas que les asigna el Maestro.
Caracter√≠sticas:
Los esclavos no toman decisiones sobre qu√© procesos ejecutar ni c√≥mo gestionar recursos.
El maestro puede representar un cuello de botella si no se gestiona eficientemente.
Ventajas:
Simplifica la coordinaci√≥n y gesti√≥n de recursos.
Ideal para sistemas especializados con tareas bien definidas (por ejemplo, procesadores de E/S o coprocesadores).
Desventajas:
Menor flexibilidad y escalabilidad en comparaci√≥n con modelos sim√©tricos.
Dependencia del Maestro: si este falla, todo el sistema puede colapsar.

23_
(a) M√©todo de planificaci√≥n m√°s sencillo para procesadores homog√©neos:
El m√©todo de planificaci√≥n m√°s sencillo es el First-Come, First-Served (FCFS) aplicado en un esquema multiprocesador. En este caso, 
los procesos son asignados a los procesadores en el orden en que llegan a la cola de procesos listos. Cada CPU selecciona el pr√≥ximo 
proceso disponible.

(b) Ventajas y desventajas de FCFS en procesadores homog√©neos:
Ventajas:
Simplicidad:
Es f√°cil de implementar y no requiere c√°lculos complejos ni estructuras adicionales.
No necesita conocer las caracter√≠sticas del proceso, como tiempo de ejecuci√≥n o requerimientos espec√≠ficos.
Baja sobrecarga:
No hay necesidad de realizar migraciones o ajustes din√°micos, reduciendo el overhead.
Equidad en el orden de llegada:
Los procesos se ejecutan en el orden en que llegaron, lo cual puede ser percibido como justo en algunos contextos.

Desventajas:
Ineficiencia en sistemas multiprocesador:
No considera las caracter√≠sticas del proceso, como si es intensivo en CPU o E/S, lo que puede llevar a un uso sub√≥ptimo de los procesadores.
Problemas con procesos largos:
Los procesos largos pueden retrasar la ejecuci√≥n de los procesos m√°s cortos (problema de convoy).
Ausencia de balanceo de carga:
Si los procesos asignados a un procesador tienen tiempos largos, otros procesadores pueden quedar subutilizados, causando desequilibrios en la carga.
No adapta prioridades:
Todos los procesos tienen el mismo trato, sin considerar escenarios donde algunos procesos puedan tener mayor urgencia o importancia.

Alternativa para mejorar FCFS en procesadores homog√©neos:
Un m√©todo m√°s eficiente podr√≠a ser Round-Robin (RR), ya que introduce tiempos compartidos y asegura que todos los procesos tengan oportunidad de 
usar la CPU, mitigando el problema de convoy y mejorando la equidad en entornos con m√∫ltiples procesadores. Sin embargo, RR implica una mayor 
complejidad que FCFS.

24_
(a) Huella de un proceso en un procesador:
La huella de un proceso hace referencia a los datos que el proceso deja en la memoria cach√© del procesador (como instrucciones, datos 
frecuentes o contextos). Si el proceso vuelve a ejecutarse en el mismo procesador, puede beneficiarse de los datos ya cargados en la 
cach√©, mejorando el rendimiento.

(b) Afinidad con un procesador:
La afinidad con un procesador se refiere a la relaci√≥n preferencial entre un proceso y un procesador espec√≠fico. En sistemas multiprocesador, 
se puede establecer que un proceso se ejecute siempre en un mismo procesador, lo que reduce el overhead de mover el proceso entre diferentes 
n√∫cleos y aprovecha la huella en la cach√©.

(c) ¬øPor qu√© podr√≠a ser mejor en algunos casos que un proceso se ejecute en el mismo procesador?
Ejecutar un proceso en el mismo procesador puede ser beneficioso porque:
Reducci√≥n del overhead de migraci√≥n: Cambiar un proceso entre procesadores implica guardar y restaurar el estado del proceso, lo que introduce 
latencia.
Mejor uso de la memoria cach√©: Mantener un proceso en el mismo procesador permite aprovechar los datos almacenados en la cach√©, reduciendo 
accesos a memoria principal y mejorando el rendimiento.

(d) ¬øPuede el usuario cambiar la afinidad de un proceso en Windows y GNU/Linux?
En Windows:
S√≠, el usuario puede cambiar la afinidad de un proceso desde el Administrador de Tareas:
Abrir el Administrador de Tareas.
Ir a la pesta√±a "Detalles".
Hacer clic derecho en el proceso deseado, seleccionar "Establecer afinidad" y elegir los n√∫cleos.

En GNU/Linux:
S√≠, se puede cambiar la afinidad usando el comando taskset. Ejemplo:
taskset -cp <lista_de_cpu> <pid>
Donde <lista_de_cpu> indica los n√∫cleos permitidos (por ejemplo, 0,1) y <pid> es el ID del proceso.

(e) Concepto de balanceo de carga (load balancing):
El balanceo de carga es una t√©cnica para distribuir el trabajo entre varios procesadores (o nodos) en un sistema multiprocesador o 
distribuido, con el objetivo de:
Maximizar el uso de los recursos disponibles.
Evitar la sobrecarga de un procesador mientras otros est√°n inactivos.
Mejorar el tiempo de respuesta y el rendimiento general del sistema.
En sistemas operativos, el balanceo puede ser centralizado (un planificador decide la distribuci√≥n) o descentralizado (cada procesador 
toma decisiones localmente).

(f) Comparaci√≥n entre afinidad y balanceo de carga:
Afinidad:
Se centra en mantener un proceso en un procesador espec√≠fico para mejorar el rendimiento aprovechando la cach√© y reduciendo el overhead de migraci√≥n.

Balanceo de carga:
Busca distribuir la carga equitativamente entre todos los procesadores para evitar que unos est√©n sobrecargados mientras otros est√°n subutilizados.

Relaci√≥n entre ambos conceptos:
La afinidad mejora el rendimiento individual de un proceso, pero puede generar desequilibrios en la carga si muchos procesos se asignan 
al mismo procesador.
El balanceo de carga prioriza la distribuci√≥n equitativa, pero puede sacrificar las ventajas de la afinidad si se decide migrar procesos 
para lograr equilibrio.
La implementaci√≥n de ambos conceptos debe equilibrar las ventajas de aprovechar la afinidad con la necesidad de mantener una carga uniforme 
en todos los procesadores.